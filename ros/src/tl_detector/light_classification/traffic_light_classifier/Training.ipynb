{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from keras.layers import Input, Flatten, Dense, Lambda, Convolution2D, MaxPooling2D, Cropping2D, Conv2D\n",
    "from keras.layers.core import Dropout\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import TensorBoard\n",
    "from PIL import Image\n",
    "import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import boto3\n",
    "import sys, getopt\n",
    "# import matplotlib\n",
    "# matplotlib.use('Agg') # Must be before importing matplotlib.pyplot or pylab!\n",
    "# import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_s3(path):\n",
    "    data =[]\n",
    "\n",
    "    with open('./csv_classes.csv') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        line_count = 0\n",
    "        for line in reader:\n",
    "            if line_count>0:\n",
    "                image = line[0]\n",
    "                color = line[1]\n",
    "                data.append(([image,color]))\n",
    "               \n",
    "            line_count+=1\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_image(bucket,sample,resize):\n",
    "    try:\n",
    "        key= sample[0]\n",
    "        image_obj = s3.Object(bucket, key)\n",
    "        image = io.BytesIO(image_obj.get()['Body'].read())\n",
    "        image = np.asarray(Image.open(image).resize((resize,resize)))\n",
    "#         image= np.asarray( Image.open(image), dtype=\"int32\" )\n",
    "        return image\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "\n",
    "\n",
    "def generator(bucket,samples,n_classes, batch_size = 32, resize=32):\n",
    "    while True:\n",
    "        for offset in range(0,len(samples), batch_size):\n",
    "            start = offset\n",
    "            end = offset+batch_size\n",
    "            batch_sample = samples[start:end]\n",
    "            images=[]\n",
    "            colors=[]\n",
    "            for sample in batch_sample:\n",
    "                #get images\n",
    "                image = get_image(bucket, sample, resize)\n",
    "                images.append(image)\n",
    "                colors.extend(keras.utils.to_categorical(sample[1], n_classes))\n",
    "\n",
    "            x = np.array(images)\n",
    "            y = np.array(colors)\n",
    "            yield shuffle(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(bucket, train_data,validation_data, num_classes,epochs, model_name, resize=32):\n",
    "    train_generator = generator(bucket, train_data,num_classes , resize=resize)\n",
    "    val_generator = generator(bucket, validation_data,num_classes, resize=resize)\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda train_generator:train_generator, input_shape=(resize,resize,3)))\n",
    "\n",
    "    model.add(Conv2D(6, kernel_size=(5,5), activation='relu',init='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(16, kernel_size=(5,5), activation='relu',init='he_normal'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(120, activation='relu',init='he_normal', name=\"d1\"))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(84,activation='relu',init='he_normal', name = \"d2\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes,activation='softmax',init='he_normal', name=\"d3\"))\n",
    "#     optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "    model.compile(optimizer='adamax', metrics=['accuracy', 'top_k_categorical_accuracy'], loss='categorical_crossentropy')\n",
    "    tensorbrd = TensorBoard('./logs/{}'.format(model_name))\n",
    "    model.fit_generator(train_generator, steps_per_epoch=int(len(train_data)/32),epochs=epochs,\\\n",
    "                        validation_steps=int(len(validation_data)/32),validation_data = val_generator,\\\n",
    "                        verbose=1, initial_epoch=0, callbacks=[tensorbrd])\n",
    "\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red: 0, Yellow : 1, Green 2\n",
    "\n",
    "def start():\n",
    "    bucket = 'capstone-trafficlights'\n",
    "    classes = ['Red', 'Yellow', 'Green']\n",
    "    model_name= 'model_v9'\n",
    "    resize = 32\n",
    "    epochs=10\n",
    "    try:\n",
    "        print(\"\\u2713 Bucket recieved: {}\".format(bucket))\n",
    "        print(\" Loading Data ... \")\n",
    "        # create a directory to store driving_log.csv of the target bucke\n",
    "        if not os.path.exists(bucket):\n",
    "            data = load_data_from_s3(bucket)\n",
    "            train_data, validation_data = train_test_split(data, test_size=0.2)\n",
    "    \n",
    "            model = run_model(bucket, train_data, validation_data, len(classes), epochs,model_name=model_name, resize=resize)\n",
    "            model.save('./{}.h5'.format(model_name))\n",
    "    except Exception as err:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\u2713 Bucket recieved: capstone-trafficlights\n",
      " Loading Data ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(6, kernel_initializer=\"he_normal\", activation=\"relu\", kernel_size=(5, 5))`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, kernel_initializer=\"he_normal\", activation=\"relu\", kernel_size=(5, 5))`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(120, kernel_initializer=\"he_normal\", activation=\"relu\", name=\"d1\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(84, kernel_initializer=\"he_normal\", activation=\"relu\", name=\"d2\")`\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, kernel_initializer=\"he_normal\", activation=\"softmax\", name=\"d3\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "136/136 [==============================] - 651s - loss: 2.3470 - acc: 0.8339 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7695 - val_acc: 0.9449 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "136/136 [==============================] - 642s - loss: 0.9791 - acc: 0.9246 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6401 - val_acc: 0.9494 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "136/136 [==============================] - 650s - loss: 0.8076 - acc: 0.9318 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.5219 - val_acc: 0.9513 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "136/136 [==============================] - 1006s - loss: 0.6191 - acc: 0.9455 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.2562 - val_acc: 0.9724 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "136/136 [==============================] - 1073s - loss: 0.5523 - acc: 0.9458 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.3217 - val_acc: 0.9642 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "136/136 [==============================] - 1013s - loss: 0.4082 - acc: 0.9566 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.2210 - val_acc: 0.9706 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "136/136 [==============================] - 1061s - loss: 0.3928 - acc: 0.9534 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.2244 - val_acc: 0.9715 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "136/136 [==============================] - 1012s - loss: 0.3497 - acc: 0.9561 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1685 - val_acc: 0.9816 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "136/136 [==============================] - 991s - loss: 0.3412 - acc: 0.9614 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.2021 - val_acc: 0.9761 - val_top_k_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "136/136 [==============================] - 1003s - loss: 0.2914 - acc: 0.9616 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.1715 - val_acc: 0.9770 - val_top_k_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
